Transformer attention mechanism 3 improves stochastic gradient descent optimization in neural network backpropagation training. 
